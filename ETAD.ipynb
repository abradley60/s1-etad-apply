{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply ETAD to a raw Sentinel-1 SLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s1etad\n",
    "from s1etad import Sentinel1Etad, ECorrectionType\n",
    "import os\n",
    "import zipfile\n",
    "import tarfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import asf_search as asf\n",
    "from scipy import constants\n",
    "from s1etad_tools.cli.slc_correct import s1etad_slc_correct_main\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the download folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLC_folder = 'data/SLC/original'\n",
    "Corrected_SLC_folder = 'data/SLC/corrected'\n",
    "ETAD_folder = 'data/ETAD'\n",
    "os.makedirs(SLC_folder, exist_ok=True)\n",
    "os.makedirs(Corrected_SLC_folder, exist_ok=True)\n",
    "os.makedirs(ETAD_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earthdata - https://urs.earthdata.nasa.gov/users/new\n",
    "earthdata_uid = ''\n",
    "earthdata_pswd = ''\n",
    "\n",
    "# Copernicus dataspace - https://dataspace.copernicus.eu/\n",
    "copernicus_uid = ''\n",
    "copernicus_pswd = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seach and download a SLC from ASF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A point over the SURAT basin \n",
    "wkt = \"POINT (150.5759  -27.0252)\"\n",
    "prod = 'SLC'\n",
    "mode = 'IW'\n",
    "start_date = '2023-11-18T00:00:00Z'\n",
    "end_date = '2023-11-20T00:00:00Z'\n",
    "\n",
    "results = asf.search(platform=[asf.PLATFORM.SENTINEL1], \n",
    "                     intersectsWith=wkt, \n",
    "                     maxResults=10, \n",
    "                     processingLevel=prod,\n",
    "                     beamMode=mode,\n",
    "                     start=start_date,\n",
    "                     end=end_date)\n",
    "print(f'number of results: {len(results)}')\n",
    "results[0].properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a session to download\n",
    "session = asf.ASFSession()\n",
    "session.auth_with_creds(earthdata_uid,earthdata_pswd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the first result\n",
    "download = True\n",
    "download_slc = results[0]\n",
    "if download:\n",
    "    slc_path = os.path.join(SLC_folder, download_slc.properties['fileName'])\n",
    "    scene = download_slc.properties['sceneName']\n",
    "    if not os.path.exists(slc_path):\n",
    "        download_slc.download(path=SLC_folder, session=session)\n",
    "    else:\n",
    "        print(f'slc already downloaded : {slc_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search and download ETAD file from copernicus dataspace\n",
    "note at the time of writing ETAD coverage is limited to mid-2023 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_download_scene_etad(scene: str, username: str, password: str, etad_dir: str = '', unzip=True):\n",
    "    \"\"\"search and download an ETAD product for a corresponding scene. \n",
    "        see - https://documentation.dataspace.copernicus.eu/APIs/OData.html\n",
    "\n",
    "    Args:\n",
    "        scene (str): scene of interest. e.g. S1A_IW_SLC__1SSH_20231119T083317_20231119T083345_051283_062FEC_0B2C\n",
    "        etad_dir (str): where to save the downloaded product\n",
    "        username (str): username for the copernicus dataspace\n",
    "        password (str): password for the copernicus dataspace\n",
    "    Returns:\n",
    "        etad_path : path to the downloaded ETAD product. None if a product was not found.\n",
    "    \"\"\"\n",
    "\n",
    "    sat, mode, prod,_, pol, start, finish = scene.split('_')[:7]\n",
    "\n",
    "    print(f'Searching Copernicus Dataspace for ETAD file...')\n",
    "    # find the ETAD using the start and end timestamps from the SLC\n",
    "    search_results = requests.get(\n",
    "        f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'ETA') and contains(Name,'{start}') and contains(Name,'{finish}')&$orderby=ContentDate/Start&$top=100\"\n",
    "        ).json()['value']\n",
    "    files = [res['Name'] for res in search_results]\n",
    "    print(f'ETAD files found {files}')\n",
    "    assert len(search_results) == 1, \"error. more than one ETAD product found for scene\"\n",
    "    prod_id = search_results[0]['Id']\n",
    "    prod_name = search_results[0]['Name']\n",
    "    etad_filename = prod_name + '.zip'\n",
    "    \n",
    "    # get a token from copernicus hub to enable download\n",
    "    data = {\n",
    "        'grant_type': 'password',\n",
    "        'username': f'{username}',\n",
    "        'password': f'{password}',\n",
    "        'client_id': 'cdse-public',\n",
    "    }\n",
    "    response = requests.post(\n",
    "        'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token', data=data)\n",
    "    access_token = response.json()['access_token']\n",
    "\n",
    "    # download the ETAD product\n",
    "    url = f\"https://zipper.dataspace.copernicus.eu/odata/v1/Products({prod_id})/$value\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "    response = session.get(url, headers=headers, stream=True)\n",
    "    etad_path = os.path.join(etad_dir, etad_filename)\n",
    "    \n",
    "    print(f'Downloding ETAD to : {etad_path}')\n",
    "    if not os.path.exists(etad_path):\n",
    "        with open(f\"{etad_path}\", \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    file.write(chunk)\n",
    "    else:\n",
    "        print(f'ETAD already downloaded')\n",
    "\n",
    "    if unzip:\n",
    "        etad_safe = etad_path.replace('.zip', '')\n",
    "        print(f'Unzipping to : {etad_safe}')\n",
    "        if not os.path.isdir(etad_safe):\n",
    "            archive = zipfile.ZipFile(etad_path, 'r')\n",
    "            archive.extractall(etad_dir)\n",
    "            archive.close()\n",
    "\n",
    "    return etad_path if not unzip else etad_safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the ETAD\n",
    "etad_path = search_download_scene_etad(\n",
    "    scene,\n",
    "    username=copernicus_uid,\n",
    "    password=copernicus_pswd,\n",
    "    etad_dir=ETAD_folder,\n",
    "    unzip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the ETAD\n",
    "See more at https://s1etad.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = Sentinel1Etad(etad_path)\n",
    "swath = eta['IW1']\n",
    "burst = swath[1]\n",
    "correction_types = list(ECorrectionType.__members__.keys())\n",
    "s1etad.ECorrectionType.__members__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get merged burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_slc.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get timestamps from the scene\n",
    "sat, mode, prod, _, pol, start, finish = scene.split('_')[0:7]\n",
    "first_time = datetime.strptime(start, \"%Y%m%dT%H%M%S\")\n",
    "last_time =  datetime.strptime(finish, \"%Y%m%dT%H%M%S\")\n",
    "# query the catalogue for a subset of the swaths\n",
    "df = eta.query_burst(first_time=first_time, last_time=last_time, product_name=slc_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set soome constants\n",
    "dy = eta.grid_spacing['y']\n",
    "dx = eta.grid_sampling['x'] * constants.c / 2\n",
    "nswaths = len(df.swathID.unique())\n",
    "vg = eta.grid_spacing['y'] / eta.grid_sampling['y']\n",
    "vmin = 2.5\n",
    "vmax = 3.5\n",
    "to_km = 1. / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the different correction layers\n",
    "for cor in correction_types:\n",
    "    print(cor)\n",
    "    fig, ax = plt.subplots(figsize=[13, 7])\n",
    "    merged_correction = eta.merge_correction(ECorrectionType.__dict__[cor],\n",
    "                                            selection=df, meter=True)\n",
    "    print(merged_correction.keys())\n",
    "    var_ = 'x' if 'x' in merged_correction.keys() else 'y'\n",
    "    merged_correction_data = merged_correction[var_]\n",
    "    vmin = np.nanmin(merged_correction_data)\n",
    "    vmax = np.nanmax(merged_correction_data)\n",
    "\n",
    "    ysize, xsize = merged_correction_data.shape\n",
    "    x_axis = np.arange(xsize) * dx * to_km\n",
    "    y_axis = np.arange(ysize) * dy * to_km\n",
    "\n",
    "    extent=[x_axis[0], x_axis[-1], y_axis[0], y_axis[-1]]\n",
    "    im = ax.imshow(merged_correction_data, origin='lower', extent=extent,\n",
    "                vmin=vmin, vmax=vmax, aspect='equal')\n",
    "\n",
    "    ax.set_xlabel('Slant Range [km]')\n",
    "    ax.set_ylabel('Azimuth [km]')\n",
    "\n",
    "    name = merged_correction['name']\n",
    "    unit = merged_correction['unit']\n",
    "\n",
    "    ax.set_title(f'Merged swaths for {name} correction ({var_})')\n",
    "    fig.colorbar(im, ax=ax, label=f'[{unit}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply ETAD corrections to a SLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application of correction from https://github.com/SAR-ARD/S1_NRB/blob/main/S1_NRB/etad.py\n",
    "def find_etad_file(scene, ETAD_dir):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        scene (str): scene. e.g. S1A_IW_SLC__1SSH_20231119T083317_20231119T083345_051283_062FEC_0B2C\n",
    "        ETAD_dir (str): locally accessible directory containing downloaded ETAD products\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    ETAD_file = None\n",
    "    sat, mode, prod,_, pol, start, finish = scene.split('_')[:7]\n",
    "    print(f'Searching local directory for ETAD product : {ETAD_dir}')\n",
    "    for f in os.listdir(ETAD_dir):\n",
    "        if all(substring in f for substring in [sat, mode, pol[-2:], start, finish]):\n",
    "            ETAD_file = f\n",
    "            print(f'ETAD found : {ETAD_file}')\n",
    "            break\n",
    "    if ETAD_file is None:\n",
    "        print('ETAD file not found')\n",
    "    return ETAD_file\n",
    "\n",
    "def process(slc_path: str, ETAD_file: str, out_dir: str, nthreads: int=4):\n",
    "    \"\"\"\n",
    "    Apply ETAD correction to a Sentinel-1 SLC product.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    slc_path: str\n",
    "        The path to the Sentinel-1 SLC.\n",
    "    etad_dir: str\n",
    "        The directory containing ETAD products. This will be searched for products using the SLC.\n",
    "    out_dir: str\n",
    "        The directory to store results. An unzipped SAFE folder structure is created.\n",
    "    nthreads: the number of threads\n",
    "        The number of threads used for processing=\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        path to the corrected SLC SAFE product.\n",
    "    \"\"\"\n",
    "    # unzip the slc if it is not already\n",
    "    if slc_path.endswith('.zip'):\n",
    "        slc_zip = slc_path\n",
    "        slc_folder = os.path.dirname(slc_zip)\n",
    "        slc_path = slc_zip.replace(\".zip\",\".SAFE\")\n",
    "        if not os.path.exists(slc_path): \n",
    "            print(f'unzipping slc to : {slc_path}')  \n",
    "            with zipfile.ZipFile(slc_zip, 'r') as zip_ref:\n",
    "                zip_ref.extractall(slc_folder)\n",
    "    \n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    slc_base = os.path.basename(slc_path).replace('.zip', '.SAFE')\n",
    "    slc_corrected = os.path.join(out_dir, slc_base)\n",
    "    if not os.path.isdir(slc_corrected):\n",
    "        start_time = time.time()\n",
    "        ext = os.path.splitext(ETAD_file)[1]\n",
    "        if ext in ['.tar', '.zip']:\n",
    "            etad_base = os.path.basename(ETAD_file).replace(ext, '.SAFE')\n",
    "            etad = os.path.join(out_dir, etad_base)\n",
    "            if not os.path.isdir(etad):\n",
    "                if ext == '.tar':\n",
    "                    archive = tarfile.open(ETAD_file, 'r')\n",
    "                else:\n",
    "                    archive = zipfile.ZipFile(ETAD_file, 'r')\n",
    "                archive.extractall(out_dir)\n",
    "                archive.close()\n",
    "        elif ext == '.SAFE':\n",
    "            etad = ETAD_file\n",
    "        else:\n",
    "            raise RuntimeError('ETAD products are required to be .tar/.zip archives or .SAFE folders')\n",
    "        print('Correcting SLC with ETAD product')\n",
    "        s1etad_slc_correct_main(s1_product=slc_path,\n",
    "                                etad_product=etad,\n",
    "                                outdir=out_dir,\n",
    "                                nthreads=nthreads,\n",
    "                                order=0)  # using the default 1 introduces a bias of about -0.5 dB.\n",
    "        t = round((time.time() - start_time), 2)\n",
    "        print(f'Time taken: {t}')\n",
    "    else:\n",
    "        print(f'ETAD corrected product already exists: {slc_corrected}')\n",
    "    return slc_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slc_corrected = process(slc_path, etad_path, out_dir=Corrected_SLC_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtc-compare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
